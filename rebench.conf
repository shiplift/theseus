# -*- mode: yaml; -*-
# Config file for ReBench
# Config format is YAML (see http://yaml.org/ for detailed spec)

# this run definition will be choosen if no parameters are given to rebench.py
standard_run: Lamb
standard_data_file: 'results/lamb.data'

# settings and requirements for statistic evaluation
statistics:
  min_runs: 10
  max_runs: 50
  confidence_level: 0.95     #all measurments lie with a probability of 95% in the convidence interval 
  error_margin: 0.005        #the size of the confidence interfal should not be larger the 0.5% of the mean value
  stop_criterium: percentage
  stop_threshold: 5

# settings for quick runs, useful for fast feedback during experiments
quick_runs:
  min_runs: 3
  max_runs: 10
  max_time: 60   # time in seconds

# definition of benchmark suites
# settings in the benchmark suite will override similar settings of the VM
benchmark_suites:
  SimpleLambBenchmarks:
    performance_reader: TimePerformance
    command: -np -n 10 -s %(input)s -w %(variable)s %(benchmark)s
    input_sizes: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,
                  18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32,
                  33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47,
                  48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62,
                  63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77,
                  78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92,
                  93, 94, 95, 96, 97, 98, 99, 100]
    benchmarks:
      - plus:
          extra_args: 1000 1000
      - plusa:
          extra_args: 1000 1000
      - mult:
          extra_args: 1000 1000
      - multa:
          extra_args: 1000 1000
      - succ:
          extra_args: 10000
      - pred:
          extra_args: 10000
      - append:
          extra_args: 10000;i:1;f:+ 10000;i:100000,f:-
      - reverse:
          extra_args: 50000;i:1,f:*
      - map:
          extra_args: succ 10000;p:1,f:succ
    variable_values: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,
                      17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30,
                      31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44,
                      45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58,
                      59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,
                      73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86,
                      87, 88, 89, 90, 91, 92, 93,94, 95, 96, 97, 98, 99, 100]

# VMs have a name and are specified by a path and the binary to be executed
# optional: the number of cores for which the runs have to be executed
virtual_machines:
  lamb-c:
    path: .
    binary: lamb-c
    cores: [1]

# define the benchmarks to be executed for a re-executable benchmark run
# special definitions done here should override benchmark suite definitions,
# and VM definitions
run_definitions:
  Lamb:
    description: >
      Default tests for lamb
    actions: benchmark
    benchmark:
      - SimpleLambBenchmarks
    #   - LambStatistics
    executions:
      - lamb-c
    reporting:
      csv_file: results/all.result.csv
      csv_raw:  results/all.data.csv
    # Test:
    #     description: >
    #         This run definition is used for testing.
    #         It should try all possible settings and the generated out
    #         will be compared to the expected one by the unit test(s)
    #     actions: profile
    #     benchmark:
    #         - TestSuite1
    #         - TestSuite2
    #     executions:
    #         # List of VMs and Benchmarks/Benchmark Suites to be run on them
    #         # benchmarks define here will override the ones defined for the
    #         # whole run the following example is equivalent to the global run
    #         # definition, but needs to be tested...
    #         - TestRunner1:
    #             benchmark: TestSuite1
    #         - TestRunner1:
    #             benchmark: TestSuite2
    #         - TestRunner2
    # TestProfiling:
    #     description: >
    #         This run is used to test the profiling run type
    #     actions: benchmark
    #     benchmark: TestSuite1
    #     input_sizes: 1
    #     executions:
    #         - CSOM
